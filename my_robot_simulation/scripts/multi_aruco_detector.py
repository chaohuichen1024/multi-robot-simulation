#!/usr/bin/env python3
import rospy
import cv2
import cv2.aruco as aruco
import numpy as np
from sensor_msgs.msg import Image, CameraInfo
from cv_bridge import CvBridge, CvBridgeError
import ast
import tf
import tf2_ros
import geometry_msgs.msg
from geometry_msgs.msg import Point, Pose, PoseArray
from std_msgs.msg import Header, Int32MultiArray

class EnhancedArucoDetector:
    def __init__(self):
        rospy.init_node('enhanced_aruco_detector', anonymous=True)
        
        self.bridge = CvBridge()
        
        # å®‰å…¨åœ°è·å–æœºå™¨äººåˆ—è¡¨å‚æ•°
        robot_names_param = rospy.get_param('~robot_names', '["robot1", "robot2", "robot3"]')
        
        # è§£ææœºå™¨äººåç§°åˆ—è¡¨
        try:
            if isinstance(robot_names_param, str):
                self.robot_names = ast.literal_eval(robot_names_param)
            else:
                self.robot_names = robot_names_param
        except:
            rospy.logwarn("æ— æ³•è§£ærobot_nameså‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            self.robot_names = ["robot1", "robot2", "robot3"]
        
        # ARç æ£€æµ‹å‚æ•°
        self.aruco_dict = aruco.Dictionary_get(aruco.DICT_6X6_250)
        self.parameters = aruco.DetectorParameters_create()
        
        # ARç å®é™…å°ºå¯¸ (0.2x0.2ç±³)
        self.marker_length = 0.2
        
        # å­˜å‚¨æ¯ä¸ªæœºå™¨äººçš„å‘å¸ƒå™¨å’Œç›¸æœºå‚æ•°
        self.image_publishers = {}
        self.camera_matrix = {}
        self.dist_coeffs = {}
        self.has_camera_info = {}
        self.undistort_maps = {}  # æ–°å¢ï¼šå­˜å‚¨ç•¸å˜çŸ«æ­£æ˜ å°„
        self.pose_publishers = {}  # æ–°å¢ï¼šARç ä½å§¿å‘å¸ƒå™¨
        
        # TFå¹¿æ’­å™¨
        self.tf_broadcaster = tf.TransformBroadcaster()
        
        # è®¾ç½®è®¢é˜…å™¨å’Œå‘å¸ƒå™¨
        self.setup_robot_connections()
        
        rospy.loginfo(f"å¢å¼ºç‰ˆARç æ£€æµ‹å™¨å·²å¯åŠ¨ï¼Œç›‘æ§æœºå™¨äºº: {self.robot_names}")
        
    def setup_robot_connections(self):
        """ä¸ºæ¯ä¸ªæœºå™¨äººè®¾ç½®è®¢é˜…å™¨å’Œå‘å¸ƒå™¨ï¼ŒåŒ…æ‹¬å‰æ–¹å’Œå³ä¾§ç›¸æœº"""
        for robot in self.robot_names:
            # åˆå§‹åŒ–ç›¸æœºå‚æ•°çŠ¶æ€
            self.has_camera_info[robot] = {
                'front': False,
                'right': False
            }
            self.camera_matrix[robot] = {
                'front': None,
                'right': None
            }
            self.dist_coeffs[robot] = {
                'front': None,
                'right': None
            }
            self.undistort_maps[robot] = {
                'front': None,
                'right': None
            }
            
            # æ„å»ºåˆæ³•çš„è¯é¢˜åç§°
            # å‰æ–¹ç›¸æœº
            front_image_topic = f"/{robot}/camera/image"
            front_camera_info_topic = f"/{robot}/camera/camera_info"
            front_result_topic = f"/aruco_detection/{robot}/front_result"
            front_pose_topic = f"/aruco_detection/{robot}/front_poses"  # æ–°å¢ï¼šå‰æ–¹ç›¸æœºARç ä½å§¿è¯é¢˜
            
            # å³ä¾§ç›¸æœº
            right_image_topic = f"/{robot}/right_camera/image_right"
            right_camera_info_topic = f"/{robot}/right_camera/camera_info_right"
            right_result_topic = f"/aruco_detection/{robot}/right_result"
            right_pose_topic = f"/aruco_detection/{robot}/right_poses"  # æ–°å¢ï¼šå³ä¾§ç›¸æœºARç ä½å§¿è¯é¢˜
            
            # è®¢é˜…å‰æ–¹ç›¸æœºè¯é¢˜
            rospy.Subscriber(front_image_topic, Image, 
                           lambda msg, robot_name=robot, camera_type='front': self.image_callback(msg, robot_name, camera_type))
            rospy.Subscriber(front_camera_info_topic, CameraInfo,
                           lambda msg, robot_name=robot, camera_type='front': self.camera_info_callback(msg, robot_name, camera_type))
            
            # è®¢é˜…å³ä¾§ç›¸æœºè¯é¢˜
            rospy.Subscriber(right_image_topic, Image, 
                           lambda msg, robot_name=robot, camera_type='right': self.image_callback(msg, robot_name, camera_type))
            rospy.Subscriber(right_camera_info_topic, CameraInfo,
                           lambda msg, robot_name=robot, camera_type='right': self.camera_info_callback(msg, robot_name, camera_type))
            
            # åˆ›å»ºç»“æœå›¾åƒå‘å¸ƒå™¨
            self.image_publishers[robot] = {
                'front': rospy.Publisher(front_result_topic, Image, queue_size=1),
                'right': rospy.Publisher(right_result_topic, Image, queue_size=1)
            }
            
            # æ–°å¢ï¼šåˆ›å»ºARç ä½å§¿å‘å¸ƒå™¨
            self.pose_publishers[robot] = {
                'front': rospy.Publisher(front_pose_topic, PoseArray, queue_size=1),
                'right': rospy.Publisher(right_pose_topic, PoseArray, queue_size=1)
            }
            
            rospy.loginfo(f"å·²è®¢é˜… {robot} å‰æ–¹ç›¸æœº: {front_image_topic}")
            rospy.loginfo(f"å·²è®¢é˜… {robot} å³ä¾§ç›¸æœº: {right_image_topic}")
    
    def camera_info_callback(self, msg, robot_name, camera_type):
        """å¤„ç†ç›¸æœºå‚æ•°ä¿¡æ¯å¹¶ç”Ÿæˆç•¸å˜çŸ«æ­£æ˜ å°„"""
        if not self.has_camera_info[robot_name][camera_type]:
            # æå–ç›¸æœºå†…å‚çŸ©é˜µ
            self.camera_matrix[robot_name][camera_type] = np.array(msg.K).reshape(3, 3)
            
            # æå–ç•¸å˜ç³»æ•°
            self.dist_coeffs[robot_name][camera_type] = np.array(msg.D)
            
            # ç”Ÿæˆç•¸å˜çŸ«æ­£æ˜ å°„ï¼ˆå®æ—¶çŸ«æ­£ç”¨ï¼‰
            image_size = (msg.width, msg.height)
            new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(
                self.camera_matrix[robot_name][camera_type],
                self.dist_coeffs[robot_name][camera_type],
                image_size, 1, image_size
            )
            
            # è®¡ç®—ç•¸å˜çŸ«æ­£æ˜ å°„
            map1, map2 = cv2.initUndistortRectifyMap(
                self.camera_matrix[robot_name][camera_type],
                self.dist_coeffs[robot_name][camera_type],
                None, new_camera_matrix, image_size, cv2.CV_16SC2
            )
            
            self.undistort_maps[robot_name][camera_type] = (map1, map2, roi)
            
            self.has_camera_info[robot_name][camera_type] = True
            rospy.loginfo(f"âœ… å·²è·å– {robot_name} {camera_type}ç›¸æœºçš„ç›¸æœºå‚æ•°å’Œç•¸å˜æ˜ å°„")
    
    def undistort_image(self, cv_image, robot_name, camera_type):
        """å¯¹å›¾åƒè¿›è¡Œå®æ—¶ç•¸å˜çŸ«æ­£"""
        if (not self.has_camera_info[robot_name][camera_type] or 
            self.undistort_maps[robot_name][camera_type] is None):
            return cv_image
        
        try:
            map1, map2, roi = self.undistort_maps[robot_name][camera_type]
            undistorted = cv2.remap(cv_image, map1, map2, cv2.INTER_LINEAR)
            
            # è£å‰ªROIåŒºåŸŸ
            x, y, w, h = roi
            if w > 0 and h > 0:
                undistorted = undistorted[y:y+h, x:x+w]
            
            return undistorted
        except Exception as e:
            rospy.logwarn(f"ç•¸å˜çŸ«æ­£å¤±è´¥: {e}")
            return cv_image
    
    def transform_pose_to_camera_frame(self, rvec, tvec):
        """
        å°†OpenCVåæ ‡ç³»ä¸‹çš„ä½å§¿è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
        OpenCV: Zå‘å‰, Yå‘ä¸‹, Xå‘å³
        ç›¸æœºåæ ‡ç³»: Xå‘å‰, Zå‘ä¸Š, Yå‘å·¦
        """
        # åˆ›å»ºä»OpenCVåˆ°ç›¸æœºåæ ‡ç³»çš„æ—‹è½¬çŸ©é˜µ
        # è¿™ä¸ªçŸ©é˜µå°†:
        #   Z(å‰) -> X(å‰)
        #   X(å³) -> -Y(å·¦) 
        #   Y(ä¸‹) -> Z(ä¸Š)
        R_cv_to_cam = np.array([
            [0, 0, 1],   # Z -> X
            [-1, 0, 0],  # X -> -Y
            [0, -1, 0]   # Y -> -Z (æ³¨æ„: è¿™é‡Œåº”è¯¥æ˜¯Y -> Z, ä½†éœ€è¦éªŒè¯)
        ])
        
        # å°†æ—‹è½¬å‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
        R_cv, _ = cv2.Rodrigues(rvec)
        
        # åº”ç”¨åæ ‡ç³»å˜æ¢
        R_cam = R_cv_to_cam @ R_cv
        
        # è½¬æ¢å¹³ç§»å‘é‡
        t_cam = R_cv_to_cam @ tvec.flatten()
        
        # å°†æ—‹è½¬çŸ©é˜µè½¬æ¢å›æ—‹è½¬å‘é‡
        rvec_cam, _ = cv2.Rodrigues(R_cam)
        
        return rvec_cam, t_cam
    
    def publish_aruco_poses(self, poses, robot_name, camera_type):
        """å‘å¸ƒæ£€æµ‹åˆ°çš„ARç ä½å§¿ä¿¡æ¯"""
        if not poses:
            return
            
        pose_array = PoseArray()
        pose_array.header = Header()
        pose_array.header.stamp = rospy.Time.now()
        
        # è®¾ç½®åæ ‡ç³»
        if camera_type == 'front':
            pose_array.header.frame_id = f"{robot_name}/camera_link"
        else:
            pose_array.header.frame_id = f"{robot_name}/right_camera_link"
        
        for pose_info in poses:
            pose = Pose()
            
            # è®¾ç½®ä½ç½® (tvec)
            tvec = pose_info['tvec'].flatten()
            pose.position.x = tvec[0]
            pose.position.y = tvec[1]
            pose.position.z = tvec[2]
            
            # è®¾ç½®æ–¹å‘ (ä»æ—‹è½¬å‘é‡è½¬æ¢ä¸ºå››å…ƒæ•°)
            rvec = pose_info['rvec']
            rotation_matrix, _ = cv2.Rodrigues(rvec)
            transform = np.eye(4)
            transform[:3, :3] = rotation_matrix
            quaternion = tf.transformations.quaternion_from_matrix(transform)
            
            pose.orientation.x = quaternion[0]
            pose.orientation.y = quaternion[1]
            pose.orientation.z = quaternion[2]
            pose.orientation.w = quaternion[3]
            
            pose_array.poses.append(pose)
        
        # å‘å¸ƒä½å§¿ä¿¡æ¯
        self.pose_publishers[robot_name][camera_type].publish(pose_array)
    
    def detect_aruco_markers_with_pose(self, cv_image, robot_name, camera_type):
        """
        æ£€æµ‹ARç å¹¶ä¼°è®¡ä½å§¿ï¼Œåœ¨å›¾åƒä¸Šç»˜åˆ¶3Dè½´å’Œè¾¹ç•Œæ¡†
        è¿”å›å¸¦æ ‡è®°çš„å›¾åƒã€æ£€æµ‹åˆ°çš„IDåˆ—è¡¨å’Œä½å§¿ä¿¡æ¯
        """
        if not self.has_camera_info[robot_name][camera_type]:
            # å¦‚æœæ²¡æœ‰ç›¸æœºå‚æ•°ï¼Œä½¿ç”¨åŸºæœ¬æ£€æµ‹
            return self.basic_detection(cv_image, robot_name, camera_type)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾åƒ
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        
        # æ£€æµ‹ARç 
        corners, ids, rejected = aruco.detectMarkers(gray, self.aruco_dict, parameters=self.parameters)
        
        detected_ids = []
        poses = []
        
        if ids is not None:
            # ä¼°è®¡ARç ä½å§¿
            rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(
                corners, self.marker_length, 
                self.camera_matrix[robot_name][camera_type], 
                self.dist_coeffs[robot_name][camera_type]
            )
            
            # å°†IDè½¬æ¢ä¸ºåˆ—è¡¨
            detected_ids = ids.flatten().tolist()
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            for i, corner in enumerate(corners):
                marker_id = ids[i][0]
                rvec = rvecs[i]
                tvec = tvecs[i]
                
                # æ ¹æ®ç›¸æœºç±»å‹é€‰æ‹©é¢œè‰²
                if camera_type == 'front':
                    color = (0, 255, 0)  # ç»¿è‰² - å‰æ–¹ç›¸æœº
                else:
                    color = (255, 0, 0)  # è“è‰² - å³ä¾§ç›¸æœº
                
                # ç»˜åˆ¶ARç è¾¹ç•Œæ¡†
                cv2.polylines(cv_image, [corner.astype(int)], True, color, 2)
                
                # ç»˜åˆ¶3Dåæ ‡è½´ï¼ˆçº¢è‰²ï¼šXï¼Œç»¿è‰²ï¼šYï¼Œè“è‰²ï¼šZï¼‰
                axis_length = self.marker_length * 0.5
                cv2.drawFrameAxes(cv_image, self.camera_matrix[robot_name][camera_type], 
                                self.dist_coeffs[robot_name][camera_type], rvec, tvec, axis_length)
                
                # è®¡ç®—ä¸­å¿ƒç‚¹ç”¨äºæ˜¾ç¤ºID
                center = corner[0].mean(axis=0).astype(int)
                
                # ç»˜åˆ¶IDæ ‡ç­¾å’Œè·ç¦»ä¿¡æ¯
                distance = np.linalg.norm(tvec)
                text = f"ID:{marker_id} {camera_type} Dist:{distance:.2f}m"
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                
                # æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(cv_image, 
                            (center[0] - text_size[0]//2 - 5, center[1] - text_size[1] - 5),
                            (center[0] + text_size[0]//2 + 5, center[1] + 5),
                            color, -1)
                
                # IDæ–‡æœ¬
                cv2.putText(cv_image, text, 
                          (center[0] - text_size[0]//2, center[1]), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                
                # è½¬æ¢åæ ‡ç³»ï¼šä»OpenCVåæ ‡ç³»åˆ°ç›¸æœºåæ ‡ç³»
                rvec_cam, tvec_cam = self.transform_pose_to_camera_frame(rvec, tvec)
                
                # å­˜å‚¨è½¬æ¢åçš„ä½å§¿ä¿¡æ¯
                poses.append({
                    'id': marker_id,
                    'rvec': rvec_cam,
                    'tvec': tvec_cam,
                    'camera_type': camera_type
                })
                
                # å‘å¸ƒTFå˜æ¢ï¼ˆä½¿ç”¨è½¬æ¢åçš„ä½å§¿ï¼‰
                self.publish_tf_transform(rvec_cam, tvec_cam, marker_id, robot_name, camera_type)
            
            # æ–°å¢ï¼šå‘å¸ƒARç ä½å§¿ä¿¡æ¯
            self.publish_aruco_poses(poses, robot_name, camera_type)
        
        return cv_image, detected_ids, poses
    
    def basic_detection(self, cv_image, robot_name, camera_type):
        """åŸºç¡€æ£€æµ‹ï¼ˆå½“æ²¡æœ‰ç›¸æœºå‚æ•°æ—¶ä½¿ç”¨ï¼‰"""
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        corners, ids, rejected = aruco.detectMarkers(gray, self.aruco_dict, parameters=self.parameters)
        
        detected_ids = []
        
        if ids is not None:
            detected_ids = ids.flatten().tolist()
            
            # æ ¹æ®ç›¸æœºç±»å‹é€‰æ‹©é¢œè‰²
            if camera_type == 'front':
                color = (0, 255, 0)  # ç»¿è‰²
            else:
                color = (255, 0, 0)  # è“è‰²
            
            for i, corner in enumerate(corners):
                marker_id = ids[i][0]
                corner = corner.astype(int)
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.polylines(cv_image, [corner], True, color, 3)
                
                center = corner[0].mean(axis=0).astype(int)
                text = f"ID:{marker_id} {camera_type}"
                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                
                cv2.rectangle(cv_image, 
                            (center[0] - text_size[0]//2 - 5, center[1] - text_size[1] - 5),
                            (center[0] + text_size[0]//2 + 5, center[1] + 5),
                            color, -1)
                
                cv2.putText(cv_image, text, 
                          (center[0] - text_size[0]//2, center[1]), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return cv_image, detected_ids, []
    
    def publish_tf_transform(self, rvec, tvec, marker_id, robot_name, camera_type):
        """å‘å¸ƒARç çš„TFå˜æ¢ï¼ŒåŒºåˆ†ä¸åŒç›¸æœº"""
        try:
            # å°†æ—‹è½¬å‘é‡è½¬æ¢ä¸ºæ—‹è½¬çŸ©é˜µ
            rotation_matrix, _ = cv2.Rodrigues(rvec)
            
            # æ„å»ºé½æ¬¡å˜æ¢çŸ©é˜µ
            transform_matrix = np.eye(4)
            transform_matrix[:3, :3] = rotation_matrix
            transform_matrix[:3, 3] = tvec.flatten()
            
            # è½¬æ¢åˆ°TFæ ¼å¼
            transform = tf.transformations.rotation_matrix(0, (0, 0, 0))  # åˆ›å»ºå•ä½çŸ©é˜µ
            transform[:3, :3] = rotation_matrix
            transform[:3, 3] = tvec.flatten()
            
            # æå–å››å…ƒæ•°
            quaternion = tf.transformations.quaternion_from_matrix(transform)
            
            # æ ¹æ®ç›¸æœºç±»å‹ç¡®å®šçˆ¶åæ ‡ç³»
            if camera_type == 'front':
                parent_frame = f"{robot_name}/camera_link"
            else:
                parent_frame = f"{robot_name}/right_camera_link"
            
            # å‘å¸ƒTFï¼Œæ·»åŠ ç›¸æœºç±»å‹å‰ç¼€
            self.tf_broadcaster.sendTransform(
                tvec.flatten().tolist(),
                quaternion.tolist(),
                rospy.Time.now(),
                f"{camera_type}_aruco_{marker_id}",
                parent_frame
            )
            
        except Exception as e:
            rospy.logwarn(f"å‘å¸ƒTFå˜æ¢æ—¶å‡ºé”™: {e}")
    
    def image_callback(self, msg, robot_name, camera_type):
        """å¤„ç†å›¾åƒå›è°ƒï¼Œå…ˆè¿›è¡Œç•¸å˜çŸ«æ­£å†è¯†åˆ«ARç """
        try:
            # è½¬æ¢ROSå›¾åƒåˆ°OpenCVæ ¼å¼
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            
            # å®æ—¶ç•¸å˜çŸ«æ­£ - åœ¨è¯†åˆ«å‰å…ˆçŸ«æ­£å›¾åƒ
            undistorted_image = self.undistort_image(cv_image, robot_name, camera_type)
            
            # æ£€æµ‹ARç ï¼ˆå¸¦ä½å§¿ä¼°è®¡ï¼‰
            result_image, detected_ids, poses = self.detect_aruco_markers_with_pose(undistorted_image, robot_name, camera_type)
            
            # åœ¨å›¾åƒå·¦ä¸Šè§’æ·»åŠ ç›¸æœºç±»å‹æ ‡è¯†
            cv2.putText(result_image, f"{camera_type.upper()} CAMERA - {robot_name}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, 
                       (255, 255, 255) if camera_type == 'front' else (255, 200, 100), 2)
            
            # æ‰“å°æ£€æµ‹ç»“æœ
            if detected_ids:
                pose_info = ""
                for pose in poses:
                    tvec = pose['tvec'].flatten()
                    pose_info += f" ID{pose['id']}: pos({tvec[0]:.2f}, {tvec[1]:.2f}, {tvec[2]:.2f})"
                
                rospy.loginfo(f"ğŸ¤– {robot_name.upper()} {camera_type.upper()}ç›¸æœº æ£€æµ‹åˆ°ARç : IDs={detected_ids}{pose_info}")
            else:
                # å‡å°‘æœªæ£€æµ‹åˆ°æ—¶çš„æ—¥å¿—è¾“å‡ºé¢‘ç‡
                current_time = rospy.get_time()
                time_key = f'last_no_detection_time_{robot_name}_{camera_type}'
                
                if not hasattr(self, time_key):
                    setattr(self, time_key, 0)
                
                if current_time - getattr(self, time_key) > 5.0:
                    if self.has_camera_info[robot_name][camera_type]:
                        rospy.loginfo(f"ğŸ” {robot_name.upper()} {camera_type.upper()}ç›¸æœº è§†é‡å†…æœªæ£€æµ‹åˆ°ARç ")
                    else:
                        rospy.logwarn(f"âš ï¸ {robot_name.upper()} {camera_type.upper()}ç›¸æœº ç­‰å¾…ç›¸æœºå‚æ•°...")
                    setattr(self, time_key, current_time)
            
            # å‘å¸ƒç»“æœå›¾åƒ
            try:
                result_msg = self.bridge.cv2_to_imgmsg(result_image, "bgr8")
                self.image_publishers[robot_name][camera_type].publish(result_msg)
            except CvBridgeError as e:
                rospy.logerr(f"å‘å¸ƒå›¾åƒæ—¶å‡ºé”™ ({robot_name} {camera_type}): {e}")
                
        except CvBridgeError as e:
            rospy.logerr(f"å›¾åƒè½¬æ¢é”™è¯¯ ({robot_name} {camera_type}): {e}")
        except Exception as e:
            rospy.logerr(f"å¤„ç†å›¾åƒæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({robot_name} {camera_type}): {e}")
    
    def run(self):
        """è¿è¡ŒèŠ‚ç‚¹"""
        rospy.loginfo("å¢å¼ºç‰ˆARç æ£€æµ‹å™¨è¿è¡Œä¸­...æŒ‰Ctrl+Cé€€å‡º")
        rospy.loginfo("æ”¯æŒå®æ—¶ç•¸å˜çŸ«æ­£å’ŒåŒç›¸æœºARç è¯†åˆ«")
        rospy.loginfo("ARç åæ ‡è¯é¢˜æ ¼å¼: /aruco_detection/{robot_name}/{front/right}_poses")
        rospy.loginfo("å·²åº”ç”¨åæ ‡ç³»è½¬æ¢: OpenCV(Zå‰,Yä¸‹,Xå³) -> ç›¸æœº(Xå‰,Zä¸Š,Yå·¦)")
        rospy.spin()

if __name__ == '__main__':
    try:
        detector = EnhancedArucoDetector()
        detector.run()
    except rospy.ROSInterruptException:
        rospy.loginfo("å¢å¼ºç‰ˆARç æ£€æµ‹å™¨å·²å…³é—­")